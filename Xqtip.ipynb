{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78TmL5VQs6tZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBazgRwVtzby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Cornell-RelaxML/qtip.git"
      ],
      "metadata": {
        "id": "AEalZe5gtzev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dao-AILab/fast-hadamard-transform.git"
      ],
      "metadata": {
        "id": "rw-okmAnt1sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-hadamard-transform\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "mo4aDL1nuTjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fast_hadamard_transform import hadamard_transform"
      ],
      "metadata": {
        "id": "GEI4G1CDudO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qtip/qtip-kernels\n",
        "\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "JFACLtqlv-iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m eval.interactive_gen --hf_path relaxml/Llama-2-13b-QTIP-3Bit --max_new_tokens 256 --streaming"
      ],
      "metadata": {
        "id": "i8cLb6Wpwp94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/qtip/requirements.txt"
      ],
      "metadata": {
        "id": "8DyfTm6MxANh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qtip/qtip-kernels\n",
        "\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "UATVRJlHxT2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/qtip"
      ],
      "metadata": {
        "id": "sZIAir_tygDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "vzOCYpbMyh-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "\n",
        "!git clone https://github.com/Cornell-RelaxML/qtip.git\n",
        "%cd qtip-kernels\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "58A1R78kyS26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m eval.interactive_gen -h"
      ],
      "metadata": {
        "id": "VGoC-L1lxDLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/qtip/qtip-kernels\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "xyzzD18wzDw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/qtip/example.sh"
      ],
      "metadata": {
        "id": "FmAVH_AYzHgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "# Load the model pipeline\n",
        "pipe = pipeline(\"text-generation\", model=\"relaxml/Llama-2-7b-chat-QTIP-2Bit\", trust_remote_code=True, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "# Use a properly formatted string as input, with do_sample\n",
        "response = pipe(\"Who are you?\", max_new_tokens=22, do_sample=True)\n",
        "\n",
        "# Print response\n",
        "print(response[0]['generated_text'])"
      ],
      "metadata": {
        "id": "uOwJ7Y5fzzHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip uninstall torchvision -y"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3WpTRG720E9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install torchvision --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Xu8Ft0gi0FOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install --force-reinstall torchvision --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "a58Mw2UN0Har"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}